{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Download dataset\n",
    "\n",
    "official PyTorch Custom Dataset > https://github.com/utkuozbulak/pytorch-custom-dataset-examples#future-updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install gdown==3.6.0\n",
    "my_file_id = '14ExLzhn9S4pYD1L0uHXj3j3uhNVp54po'\n",
    "!gdown https://drive.google.com/uc?id={my_file_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bulid torch dataloder with custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load db\n",
    "def load_data(mat_path):\n",
    "  d = loadmat(mat_path)\n",
    "\n",
    "  return d[\"image\"], d[\"age\"][0]\n",
    "\n",
    "image, age = load_data('wiki_db.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create torch custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        data = data.transpose((0,3,1,2))\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "batch_size = 32\n",
    "validation_split = .2\n",
    "dataset_size = len(age)\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "indices = {'train':indices[split:], 'valid':indices[:split]}\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "sampler = {x: SubsetRandomSampler(indices[x]) for x in ['train', 'valid']}\n",
    "dataset = MyDataset(image, age) #instant dataset\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                                           sampler=sampler[x]) for x in ['train', 'valid']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "#e.g.\n",
    "model = models.densenet121(pretrained= True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 512)),\n",
    "                          ('Relu', nn.ReLU()),\n",
    "                          ('dropout', nn.Dropout(0.3)),\n",
    "                          ('fc2', nn.Linear(512,101))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001, amsgrad=True)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "#e.g.\n",
    "num_epochs = 15\n",
    "device = 'cuda'\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "model.to(device)\n",
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(indices[phase])\n",
    "        epoch_acc = running_corrects.double() / len(indices[phase])\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc))\n",
    "        \n",
    "        # deep copy the model\n",
    "        if phase == 'valid':\n",
    "          val_losses.append(running_loss/len(indices[phase]))\n",
    "          if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "          train_losses.append(running_loss/len(indices[phase]))\n",
    "            \n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
